% !TeX root = ../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Introducción
%*******************************************************

% \manualmark
% \markboth{\textsc{Introducción}}{\textsc{Introducción}} 

\chapter{Resumen}

%De acuerdo con la comisión de grado, el TFG debe incluir una introducción en la que se describan claramente los objetivos previstos inicialmente en la propuesta de TFG, indicando si han sido o no alcanzados, los antecedentes importantes para el desarrollo, los resultados obtenidos, en su caso y las principales fuentes consultadas.

%Ver archivo \texttt{preliminares/introduccion.tex}

Este proyecto se centra en el estudio de una subárea del aprendizaje profundo: el aprendizaje adversario. El objetivo principal es analizar las vulnerabilidades inherentes en modelos de redes neuronales y desarrollar algoritmos que mejoren la seguridad frente a ataques adversarios. Inicialmente, se introduce brevemente la teoría fundamental de las redes neuronales y se presentan las taxonomías clásicas de problemas en el contexto del aprendizaje adversario.

La memoria se divide en tres secciones principales:
\begin{enumerate}
    \item \textbf{Análisis Teóricos}: Se exploran las posibles vulnerabilidades en las redes neuronales desde una perspectiva teórica, utilizando desarrollos en probabilidad y geometría para fundamentar las hipótesis sobre las debilidades de estos modelos.
    \item \textbf{Algoritmos y Taxonomía}: Se revisan y clasifican los algoritmos existentes para ataques y defensas bajo la taxonomía causativo-reactivo, incluyendo una sección dedicada a modelos de lenguaje grande (LLM) debido a su creciente importancia.
    \item \textbf{Experimentación}: Se implementan y evalúan varios algoritmos de ataque en escenarios simulados, específicamente en sistemas de reconocimiento de señales en vehículos autónomos. Se propone un algoritmo basado en metaheurísticas, demostrando la efectividad variable de diferentes tipos de ataques dependiendo del contexto.
\end{enumerate}

El proyecto concluye con una discusión sobre los hallazgos, la importancia de avanzar en la interpretabilidad de los modelos, y la necesidad de desarrollar técnicas más robustas frente a nuevos tipos de ataques.


\endinput
